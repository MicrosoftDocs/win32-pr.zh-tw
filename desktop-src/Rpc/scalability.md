---
title: 延展性
description: 延展性
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- 延展性
- 遠端程序呼叫 RPC、最佳作法、擴充性
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 09/16/2019
ms.locfileid: "103840620"
---
# <a name="scalability"></a>延展性

這一期的擴充性通常是誤用的。 在本節中，會提供雙重定義：

-   擴充性是能夠在多處理器系統上充分利用可用的處理能力， (2、4、8、32或更多處理器) 。
-   擴充性是提供大量用戶端服務的能力。

這兩個相關的定義通常稱為 *向上* 延展。 本主題結尾提供 *相應* 放大的秘訣。

這段討論僅著重于撰寫可擴充的伺服器，而不是可擴充的用戶端，因為可擴充的伺服器是更常見的需求。 本節也可解決 RPC 和 RPC 伺服器內容中的擴充性。 這裡不會討論擴充性的最佳做法，例如減少爭用、避免全域記憶體位置的頻繁快取遺漏，或避免共用錯誤。

## <a name="rpc-threading-model"></a>RPC 執行緒模型

當伺服器收到 RPC 呼叫時，會在 RPC 提供的執行緒上呼叫 server 常式 (管理員常式) 。 RPC 使用調適型執行緒集區，隨著工作負載波動而增加和減少。 從 Windows 2000 開始，RPC 執行緒集區的核心是完成通訊埠。 完成埠及其 RPC 的使用方式會針對零到低度的爭用伺服器常式進行調整。 這表示 RPC 執行緒集區會主動增加服務執行緒的數目（如果有封鎖執行緒）。 它會在封鎖很罕見的了推測: 上運作，而且如果執行緒遭到封鎖，這就是可快速解決的暫時性狀況。 這種方法可提高低爭用伺服器的效率。 例如，在透過高速系統區域網路存取的八處理器550MHz 伺服器上運作的 void 呼叫 RPC 伺服器 (SAN) 會提供超過200個遠端用戶端每秒30000次的 void 呼叫。 這代表每小時108000000個以上的呼叫。

結果就是主動執行緒集區實際上是以伺服器上的爭用很高的方式來進行。 為了說明，請想像用來從遠端存取檔案的繁重伺服器。 假設伺服器採用最簡單的方法：它只會在 RPC 叫用伺服器常式的執行緒上同步讀取/寫入檔案。 此外，假設我們有四個處理器伺服器可提供許多用戶端。

伺服器會從五個執行緒開始 (這實際上不同，但有五個執行緒用於簡化) 。 一旦 RPC 挑選第一個 RPC 呼叫，就會將呼叫分派給 server 常式，而伺服器常式會發出 i/o。 它不常遺失檔案快取，然後封鎖等候結果。 一旦封鎖，第五個執行緒便會被釋放以收取要求，而第六個執行緒會建立為熱待命。 假設每10個 i/o 作業遺漏了快取，而且會封鎖100毫秒 (任意時間值) ，並假設四個處理器伺服器每秒提供20000個呼叫 (5000 每個處理器) 的呼叫，則簡化的模型會預測每個處理器會產生大約50的執行緒。 這會假設將封鎖每隔2毫秒的呼叫，並在100毫秒後再次釋放第一個執行緒，讓集區在大約200個執行緒 (50 每個處理器) 。

實際的行為較為複雜，因為大量執行緒會造成額外的內容切換，而使伺服器變慢，而且也會降低建立新執行緒的速率，但基本概念很清楚。 當伺服器上的執行緒開始封鎖並等候 (是 i/o 或資源) 的存取權時，執行緒的數目會很快就會出現。

RPC 和閘道連入要求的完成埠將嘗試維持伺服器中可用的 RPC 執行緒數目，使其等於電腦上的處理器數目。 這表示在四個處理器的伺服器上，一旦執行緒回到 RPC 之後，如果有四個或更多可用的 RPC 執行緒，就不允許第五個執行緒挑選新的要求，而是在其中一個目前可用的執行緒區塊時，會進入熱待命狀態。 如果第五個執行緒的等候時間夠長，但沒有可使用的 RPC 執行緒數目低於處理器數目，就會釋出，也就是執行緒集區將會減少。

想像有許多執行緒的伺服器。 如先前所述，RPC 伺服器最後會有許多執行緒，但只有執行緒經常封鎖。 線上程經常封鎖的伺服器上，會立即從熱待命清單取出傳回至 RPC 的執行緒，因為所有目前可用的執行緒都會封鎖，而且會獲得處理要求。 當執行緒封鎖時，核心中的執行緒發送器會將內容切換到另一個執行緒。 此內容切換本身會耗用 CPU 迴圈。 下一個執行緒將會執行不同的程式碼、存取不同的資料結構，而且會有不同的堆疊，這表示 (L1 和 L2 快取的記憶體快取命中率) 將會較低，而導致執行速度變慢。 許多執行的執行緒都會同時增加現有資源的爭用，例如堆積、伺服器程式碼中的重要區段等等。 這會進一步將爭用增加為資源形式的群組。 如果記憶體不足，由大量和不斷成長的執行緒所行使的記憶體壓力會導致分頁錯誤，這會進一步增加執行緒封鎖的速率，並造成更多的執行緒建立。 根據它封鎖的頻率，以及可用的實體記憶體數量，伺服器可能會以較低的效能層級穩定，並以高內容交換器速率穩定，也可能會降低只重複存取硬碟和內容切換的時間點，而不會執行任何實際工作。 當然，這種情況並不會顯示在輕量工作負載下，但繁重的工作負載很快就會將問題帶入介面中。

如何防止這種情況？ 如果執行緒預期會封鎖、將呼叫宣告為非同步，並且在要求進入伺服器常式之後，將其佇列到使用 i/o 系統和/或 RPC 非同步功能的背景工作執行緒集區。 如果伺服器正在進行 RPC 呼叫，請將它們設為非同步，並確定佇列的成長太大。 如果伺服器常式正在執行檔案 i/o，請使用非同步檔案 i/o 來將多個要求排入 i/o 系統的佇列，而且只有幾個執行緒將它們排入佇列，然後挑選結果。 如果伺服器常式正在進行網路 i/o，請使用系統的非同步功能來發出要求，並以非同步方式挑選回復，並盡可能使用最少的執行緒。 當 i/o 完成，或執行伺服器的 RPC 呼叫完成時，請完成傳遞要求的非同步 RPC 呼叫。 如此一來，伺服器就能以最少的執行緒執行，進而提高效能以及伺服器可以服務的用戶端數目。

## <a name="scale-out"></a>擴增

您可以將 RPC 設定為使用網路負載平衡 (NLB) 如果設定 NLB，讓指定用戶端位址的所有要求都移至相同的伺服器。 由於每個 RPC 用戶端會開啟連接集區 (如需詳細資訊，請參閱 [RPC 和網路](rpc-and-the-network.md)) ，來自指定用戶端集區的所有連接都必須在相同的伺服器電腦上。 只要符合這種情況，您就可以將 NLB 叢集設定為一部大型 RPC 伺服器，而且可能會有絕佳的擴充性。

 

 




